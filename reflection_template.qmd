---
title: "STAT 331 Portfolio"
author: "Andrew Cho"
format: 
  html:
    code-tools: true
    code-fold: true
    embed-resources: true
    theme: darkly
    toc: true
editor: source
execute:
  echo: true
  error: false
  warning: false
  message: false
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be a C.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Example 1

```{r}
#| label: wd-1-csv-1c

# Lab 5: Import gym membership data

gym_member <- read_csv("data/gym_member.csv")
```

-   `csv` Example 2

```{r}
#| label: wd-1-csv-2

# Lab 3: Q2
#EDIT: removed here and used read_csv

teacher_evals <- read_csv("downloads/data/teacher_evals.csv")
```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

#PA 4: read xlsx data

library(readxl)
military <- read_xlsx("gov_spending_per_capita.xlsx",
                      sheet = "Share of Govt. spending",
                      skip  = 7,
                      n_max = 190,
                      na = c(". .", "xxx", "..")
                      )
```

**WD-2: I can select necessary columns from a dataset.**

-   Example selecting specified columns

```{r}
#| label: wd-2-ex-1

# Lab 3 Q5

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(
    course_id, teacher_id, question_no, no_participants,
    resp_share, SET_score_avg, percent_failed_cur,
    academic_degree, seniority, sex
  )

glimpse(teacher_evals_clean)
```

-   Example removing specified columns

```{r}
#| label: wd-2-ex-2

# Lab 3 Q5

teacher_evals_small <- teacher_evals |>
  select(-dept, -division)
```

-   Example selecting columns based on logical values (e.g., `starts_with()`, `ends_with()`, `contains()`, `where()`)

```{r}
#| label: wd-2-ex-3

#Lab 4 Q7

  plot_data <- ca_childcare |>
  select(
    region, 
    study_year, 
    starts_with("mc_")
  ) |>
  pivot_longer(
    cols      = starts_with("mc_"),
    names_to  = "age_group",
    values_to = "price_weekly"
  )
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-3-numeric-ex-1

# Lab 3 Q5

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(
    course_id, teacher_id, question_no, no_participants,
    resp_share, SET_score_avg, percent_failed_cur,
    academic_degree, seniority, sex
  )
```

-   Numeric Example 2

```{r}
#| label: wd-3-numeric-ex-2

#Lab 3 Q11

yr1_by_course <- teacher_evals_clean |>
  filter(seniority == 1)
```

-   Character Example 1 (any context)

```{r}
#| label: wd-3-character

#Lab 5, witness on franklin

witness2 <- person |>
filter(address_street_name == "Franklin Ave",
str_detect(name, "^Ann"))
```

-   Character Example 2 (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

#Lab 5, members starting with '48Z'

members_48Z <- get_fit_now_member |>
mutate(id = as.character(id)) |>
filter(str_starts(id, "48Z"))
```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

#Lab 5, convert to date and filter jan 9, 2018

checkins_0109 <- get_fit_now_check_in |>
  mutate(
    membership_id = as.character(membership_id),
    # EDIT: Treat check_in_date as date
    check_in_date = ymd(as.character(check_in_date))
  ) |>
  filter(check_in_date == ymd("2018-01-09"))
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-4-numeric-ex-1

# Lab 10 Q3: random babies sim
# EDIT: use mutate() to create numeric var

prop_table <- tibble(correct = results) |>
  count(correct) |>
  mutate(proportion = n / sum(n))
  prop_table
```

-   Numeric Example 2

```{r}
#| label: wd-4-numeric-ex-2

#Lab 5, check in date as int

checkins_0109 <- get_fit_now_check_in |>
  mutate(
  membership_id = as.character(membership_id),
  check_in_date = as.integer(check_in_date)
  ) |>
filter(check_in_date == 20180109)
```

-   Factor Example 1 (renaming levels)

```{r}
#| label: wd-4-factor-ex-1

#Lab 4 Q7

plot_data <- ca_childcare |>
select(region, study_year, mc_infant, mc_toddler, mc_preschool) |>
pivot_longer(
cols = c(mc_infant, mc_toddler, mc_preschool),
names_to = "age_group",
values_to = "price_weekly"
) |>
mutate(
age_group = recode(age_group,
mc_infant = "Infant",
mc_toddler = "Toddler",
mc_preschool = "Preschool"),
age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
region = fct_recode(region, "Los Angeles County" = "Los Angeles"),
region = fct_relevel(
region,
"San Francisco Bay Area",
"Orange",
"Los Angeles County",
"Northern San Joaquin Valley",
"Central Coast",
"Inland Empire",
"Superior California",
"Southern San Joaquin Valley",
"San Diego-Imperial",
"North Coast"
)
)
```

-   Factor Example 2 (reordering levels)

```{r}
#| label: wd-4-factor-ex-2

# Lab 4 Q7

plot_data <- ca_childcare |>
  select(region, study_year, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
    cols      = c(mc_infant, mc_toddler, mc_preschool),
    names_to  = "age_group",
    values_to = "price_weekly"
  ) |>
  mutate(
    age_group = recode(
      age_group,
      mc_infant    = "Infant",
      mc_toddler   = "Toddler",
      mc_preschool = "Preschool"
    ),
    age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
    region    = fct_recode(region, "Los Angeles County" = "Los Angeles"),
    region    = fct_relevel(
      region,
      "San Francisco Bay Area",
      "Orange",
      "Los Angeles County",
      "Northern San Joaquin Valley",
      "Central Coast",
      "Inland Empire",
      "Superior California",
      "Southern San Joaquin Valley",
      "San Diego-Imperial",
      "North Coast"
    )
  )
```

-   Character (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

#Lab 5, clean witness name

witness2 <- person |>
  filter(
    address_street_name == "Franklin Ave",
    str_detect(name, "^Ann")
  ) |>
  mutate(
    name_clean = str_to_title(name)
  )
```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

#Lab 5, add month() with lubridate

checkins_0109 <- get_fit_now_check_in |>
  mutate(
    membership_id = as.character(membership_id),
    check_in_date = ymd(as.character(check_in_date)),
    check_in_month = month(check_in_date, label = TRUE)
  ) |>
  filter(check_in_date == ymd("2018-01-09")
         )
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()` Example 1

```{r}
#| label: wd-5-left-ex-1

#Lab 4 Q3
#EDIT: revised to avoid nested functions

tax_rev_clean <- tax_rev |>
rename(
county_name = entity_name,
study_year = year
)
ca_childcare_with_tax <- ca_childcare |>
left_join(tax_rev_clean, by = c("county_name", "study_year")
          )
```

-   `right_join()` Example 1

```{r}
#| label: wd-5-right-ex-1

# Lab 4 right join on tax and childcare
#EDIT: updated syntax and renamed tax cols

tax_rev_clean <- tax_rev |>
  rename(
  county_name = entity_name,
  study_year = year
  )
tax_enriched <- tax_rev_clean |>
  right_join(ca_childcare, by = c("county_name",   
                                  "study_year")
             )
```

-   `left_join()` **or** `right_join()` Example 2

```{r}
#| label: wd-5-left-right-ex-2

#Lab 5: attaching income to masterminds
#EDIT: utilized second mutate join using a left join

tax_rev_clean <- tax_rev |>
  rename(
  county_name = entity_name,
  study_year = year
  )

tax_enriched <- tax_rev_clean |>
  right_join(ca_childcare, by = c("county_name", 
                                  "study_year")
             )
```

-   `inner_join()` Example 1

```{r}
#| label: wd-5-inner-ex-1

# Lab 4 Q2

ca_childcare <- counties |>
  filter(state_abbreviation == "CA") |>
  inner_join(
    childcare_costs |>
      filter(study_year >= 2008, study_year <= 2018),
    by = "county_fips_code"
  )
```

-   `inner_join()` Example 2

```{r}
#| label: wd-5-inner-ex-2

# Lab 5: get witness interview transcripts w/ names
#EDIT: fixed inner_join used for linking people & interviews

witness_interviews <- interview |>
  inner_join(person |> select(id, name), by = 
               c("person_id" = "id")) |>
  select(name, transcript)
witness_interviews
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

#Lab 5: semi_join members checked in on date
#EDIT: avoided nested function by filtering in a seperate object

witness_interviews <- interview |>
  inner_join(person |> select(id, name), by = c
             ("person_id" = "id")) |>
  select(name, transcript)
witness_interviews
```

-   `anti_join()`

```{r}
#| label: wd-6-anti

#Lab 5, anti join members who did not check in on jan 9 2018
#EDIT: avoided nested function by filtering seperately

checkins_2018_01_09 <- get_fit_now_check_in |>
  filter(check_in_date == 20180109)
gym_members_checked_in <- get_fit_now_member |>
  semi_join(checkins_2018_01_09, by = c("id" = 
                                        "membership_id")
            )
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

# Lab 4 Q7

plot_data <- ca_childcare |>
  select(region, study_year, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
    cols      = c(mc_infant, mc_toddler, mc_preschool),
    names_to  = "age_group",
    values_to = "price_weekly"
  )
```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

# Lab 4 Q5
#EDIT: clearer column names both before and after pivot

mhi_by_region <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
    summarise(
    median_hh_income = median(hh_income, na.rm = TRUE),
    .groups = "drop"
) |>
pivot_wider(
  names_from = study_year,
  values_from = median_hh_income,
  names_prefix = "mhi_"
    )

mhi_by_region
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

The following assignments satisfy the above criteria:

-   Lab 1 - learned how to structure Quarto doc and how to build reproducible reports in RStudio
-   Lab 2 - learned how to ensure the workflow from data import, cleaning, then visualization was reproducible
-   Lab 3 - Used here package to load teacher evals dataset and produced clean, readable tables
-   Lab 4 - Used here package and joined multiple datasetes ensuring all files attached properly
-   Challenge 7 - Used here package for data and used set seeds to ensure reproducibility

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

# Lab 2 Q4: scatterplot of weight vs hindfoot length

ggplot(
  data = surveys,
  aes(x = weight, y = hindfoot_length)
) +
  geom_point(alpha = 0.3, color = "steelblue") +
  labs(
    x = "Weight (grams)",
    y = "Hindfoot Length (mm)",
    title = "Relationship Between Weight and Hindfoot Length"
  )
```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

# Lab 3 Q5

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(
    course_id, teacher_id, question_no, no_participants,
    resp_share, SET_score_avg, percent_failed_cur,
    academic_degree, seniority, sex
  )

glimpse(teacher_evals_clean
        )
```

-   Example of function formatting

```{r}
#| label: r-2-3

#Lab 7 Q4
#EDIT: formatted the function properly

condition_index <- function(weight_g, length_cm) {
weight_g / (length_cm^3) * 100
}
condition_index(150, 20)
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example (any context)

```{r}
#| label: r-3-example

# Lab 2: Filtering invalid inputs to prevent errors

surveys_filtered <- surveys |>
  filter(weight > 0, hindfoot_length > 0) |>
  filter(weight <= 65)

surveys_filtered
```

-   Example (function stops)

```{r}
#| label: r-3-function-stops

#Lab 7 Q4

rescale_01 <- function(x) {
  stopifnot(is.numeric(x))
  stopifnot(length(x) > 1)
  rng  <- range(x, na.rm = TRUE, finite = TRUE)
  span <- rng[2] - rng[1]
  if (span == 0) {
    return(
      case_when(
        is.na(x)     ~ NA,
        is.finite(x) ~ 0,
        TRUE         ~ NA
      )
    )
  }
  case_when(
    is.na(x)     ~ NA,
    x == -Inf    ~ 0,
    x ==  Inf    ~ 1,
    is.finite(x) ~ (x - rng[1]) / span
  )
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   At least two numeric variables

```{r}
#| label: dvs-1-num

# Lab 2 Q4–8

library(tidyverse)

ggplot(surveys, aes(x = weight, y = hindfoot_length)) +
  geom_point(alpha = 0.3) + 
  facet_wrap(~ species) + 
  labs(
    title    = "Relationship Between Weight and Hindfoot Length by Species",
    subtitle = "Hindfoot Length (mm)",
    x        = "Weight (grams)",
    y        = ""
  )
```

-   At least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

#Lab 2 Q10-15

ggplot(surveys, aes(x = species, y = weight)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(color = "steelblue", alpha = 0.4) +
labs(x = "species", y = "weight (grams)", title = "Rodent weights by species") +
theme(axis.text.x = element_text(angle = 45))
```

-   At least two categorical variables

```{r}
#| label: dvs-2-cat

#Lab 3 Challenge 2
#EDIT: added a percent scale on y-axis for proportions

ggplot(teacher_evals_compare, aes(x = sen_level, fill = set_level)) +
geom_bar(position = "fill") +
scale_y_continuous(labels = percent_format(accuracy = 1)) +
labs(
title = "Evaluation of Teachers' Use of Activities",
x = "Years of Experience",
y = "Percent of Responses",
fill = "Evaluation Rating"
) +
scale_fill_manual(values = c("excellent" = "#9834eb", "standard" = "#d46c22")) +
theme_minimal() +
theme(
legend.position = "top",
legend.title = element_text(face = "bold"),
plot.title = element_text(hjust = 0.5, face = "bold")
)
```

-   Dates (time series plot)

```{r}
#| label: dvs-1-date

# Lab 4 Q7

ggplot(plot_data, aes(x = study_year, y = price_weekly, color = region)) +
  geom_point(alpha = 0.5, size = 1.5) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  labs(
    title  = "Weekly Median Price for Center-Based Childcare",
    x      = "Year",
    y      = "Median Weekly Price",
    color  = "California Region"
  ) +
  facet_wrap(~ age_group, nrow = 1
             )
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can modify my plot theme to be more readable

```{r}
#| label: dvs-2-ex-1

# Lab 3 Challenge 2

ggplot(teacher_evals_compare, aes(x = sen_level, fill = set_level)) +
  geom_bar(position = "fill") +
  labs(
    title = "Evaluation of Teachers' Use of Activities",
    x     = "Years of Experience",
    y     = "Percentage",
    fill  = "Evaluation Rating"
  ) +
  scale_fill_manual(values = c("excellent" = "#9834eb", "standard" = "#d46c22")) +
  theme_minimal() +
  theme(
    legend.position = "top",
    legend.title    = element_text(face = "bold"),
    plot.title      = element_text(hjust = 0.5, face = "bold")
  )
```

-   I can modify my colors to be accessible to anyone's eyes

```{r}
#| label: dvs-2-ex-2

# Lab 2 Q10–15
#EDIT: used colorblind safe color palette

library(ggplot2)
ggplot(surveys, aes(x = species, y = weight, fill = species)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.4, width = 0.2) +
  scale_fill_brewer(palette = "Set2") +
    labs(
      x = "Species",
      y = "Weight (grams)",
      title = "Rodent Weights by Species (Colorblind
              -Friendly Palette)",
              fill = "Species"
              ) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

-   I can modify my plot titles to clearly communicate the data context

```{r}
#| label: dvs-2-ex-3

#Lab 1 Q6
#EDIT: clarified plot titles to communicate context

library(ggplot2)
library(dplyr)
ggplot(ToothGrowth, aes(x = supp, y = len)) +
geom_boxplot() +
  labs(
  title = "Tooth Length by Supplement Type",
  x = "Supplement Type",
  y = "Tooth Length (mm)"
        )
ToothGrowth |>
  mutate(dose = as.factor(dose)) |>
    ggplot(aes(x = dose, y = len)) +
    geom_boxplot() +
      labs(
      title = "Tooth Length by Vitamin C Dose",
      x = "Dose (mg/day)",
      y = "Tooth Length (mm)"
            )
```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-ex-4

#Lab 2 Q10-15
#EDIT: improved text readability and orientation

library(ggplot2)
ggplot(surveys, aes(x = species, y = weight)) +
geom_boxplot(outlier.shape = NA) +
labs(
title = "Rodent Weights by Species",
x = "Species",
y = "Weight (grams)"
) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
axis.title = element_text(size = 11, face = "bold"),
plot.title = element_text(size = 13, face = "bold")
)
```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-ex-5

# Lab 3 Challenge 2
#EDIT: reordered legend to match fill colors

teacher_evals_ordered <- teacher_evals_compare |>
  mutate(
  set_level = fct_relevel(set_level, "standard", 
                          "excellent")
  )

ggplot(teacher_evals_ordered, aes(x = sen_level, fill = set_level)) +
  geom_bar(position = "fill") +
    scale_fill_manual(
    values = c(
    "standard"  = "#999999",
    "excellent" = "#1b9e77"
                )
) +
labs(
title = "Evaluation Ratings by Teacher Experience",
x     = "Years of Experience",
y     = "Percent of Responses",
fill  = "Rating"
      ) +
theme_minimal() +
theme(legend.position = "top")
```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors (Example 1)

```{r}
#| label: dvs-3-1-ex-1

# Lab 3 Challenge 2

ggplot(teacher_evals_compare, aes(x = sen_level, fill = set_level)) +
  geom_bar(position = "fill") + 
  scale_fill_manual(values = c("excellent" = "#9834eb", "standard" = "#d46c22")) +
  labs(title = "Evaluation of Teachers' Use of Activities") +
  theme_minimal()
```

-   I can use non-standard colors (Example 2)

```{r}
#| label: dvs-3-1-ex-2

#Lab 2 Q10-15
#EDIT: added a manually defined color palette 

library(ggplot2)
species_palette <- c(
"BA" = "#ffd92f",
"DM" = "#e78ac3",
"DO" = "#8da0cb",
"DM" = "#fc8d62"
)
ggplot(surveys, aes(x = species, y = weight, fill = species)) +
geom_boxplot(outlier.shape = NA) +
scale_fill_manual(values = species_palette) +
labs(
title = "Rodent Weights by Species (Custom Palette)",
x = "Species",
y = "Weight (grams)",
fill = "Species"
)
```

-   I can use annotations (e.g., `geom_text()`)

```{r}
#| label: dvs-3-2

# Lab 10 Q3: proportion of correct baby matches
#EDIT: added text annotations by using geom_text

prop_table <- tibble(correct = results) |>
count(correct) |>
mutate(proportion = n / sum(n))

ggplot(prop_table, aes(x = correct, y = proportion)) +
geom_col() +
geom_text(
aes(label = percent(proportion, accuracy = 0.1)),
vjust = -0.3,
size  = 3
) +
scale_y_continuous(labels = percent_format(accuracy = 1)) +
labs(
title = "Proportion of Correct Matches in Random Baby Assignments",
x     = "Number of Correct Matches",
y     = "Proportion"
)
```

-   I can choose creative geometries (e.g., `geom_segment()`, `geom_ribbon)()`)

```{r}
#| label: dvs-3-3

# Lab 10: visualizing confidence interval coverage
#EDIT: used creative geom, geom_errorbar, for CI

library(ggplot2)

true_beta1 <- 0.5

ci_results_labeled <- ci_results |>
mutate(
iteration = row_number(),
covered   = if_else(cover == 1, "Yes", "No")
)

ggplot(ci_results_labeled,
aes(x = iteration, y = estimate,
ymin = conf.low, ymax = conf.high,
color = covered)) +
geom_errorbar(width = 0) +
geom_point(size = 0.7) +
geom_hline(yintercept = true_beta1, linetype = "dashed") +
labs(
title = "95% Confidence Intervals Across Simulations",
subtitle = "Colored by whether the true slope is covered",
x       = "Simulation",
y       = "Estimated Slope",
color   = "Covers True Slope?"
)
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

# Lab 4: median household income by region and year
#EDIT: added group sumary with summarize() 

mhi_by_region_long <- ca_childcare |>
filter(study_year %in% c(2008, 2018)) |>
group_by(region, study_year) |>
summarise(
median_hh_income = median(hh_income, na.rm = TRUE),
.groups          = "drop"
)

mhi_by_region_long
```

-   Example using `across()`

```{r}
#| label: dvs-4-across

# Lab 7: counting missing values in each column of fish data
#EDIT: used a clearer across() example to summarize missingness

rows_missing <- fish |>
mutate(all_missing = if_any(everything(), is.na)) |>
summarise(rows_missing = sum(all_missing))

vars_missing <- fish |>
summarise(
across(everything(), ~ sum(is.na(.x)))
)

rows_missing
vars_missing
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

# Lab 3 Q10

q1_by_course <- teacher_evals_clean |>
  filter(question_no == 901) |>
  group_by(teacher_id, course_id) |>
  summarise(q1_course_mean = mean(SET_score_avg, na.rm = TRUE), .groups = "drop")

q1_stats <- q1_by_course |>
  group_by(teacher_id) |>
  summarise(
    n_courses = n(),
    q1_mean   = mean(q1_course_mean, na.rm = TRUE),
    .groups   = "drop"
  ) |>
  filter(n_courses >= 3)

q1_stats
```

-   Example 2

```{r}
#| label: dvs-5-2

# Lab 4 Q6

region_infant_2018 <- ca_childcare |>
  filter(study_year == 2018) |>
  group_by(region) |>
  summarize(median_mc_infant = median(mc_infant, na.rm = TRUE), .groups = "drop") |>
  slice_min(median_mc_infant, n = 1, with_ties = FALSE)

region_income_min_2018 <- mhi_by_region |>
  slice_min(`2018`, n = 1, with_ties = FALSE) |>
  select(
    region_lowest_income_2018 = region,
    lowest_income_2018        = `2018`
  )

region_infant_2018
region_income_min_2018
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   I can modify my column names to clearly communicate the data context

```{r}
#| label: dvs-6-ex-1

# Lab 4: median household income table
#EDIT: Renamed columns to communicate data more clearly

mhi_by_region |>
rename(
median_income_2008 = mhi_2008,
median_income_2018 = mhi_2018
)
```

-   I can modify the text in my table to be more readable (e.g., bold face for column headers)

```{r}
#| label: dvs-6-ex-2

# Lab 9: demographics of professors table.
#EDIT: changed summary into formatted table with bold headers

teacher_evals |>
select(`Academic Degree`, Seniority, Sex) |>
pivot_longer(everything(), names_to = "Demographic", values_to = "Group") |>
filter(!is.na(Group)) |>
count(Demographic, Group, name = "Count") |>
group_by(Demographic) |>
mutate(`%` = Count / sum(Count)) |>
arrange(Demographic, Group) |>
mutate(
`%`   = sprintf("%.2f%%", 100 * `%`),
Group = as.character(Group)
) |>
kable(
caption   = "Demographics of Professors",
col.names = c("**Demographic**", "**Group**", "**Count**", "**%**")
) |>
add_header_above(c(" " = 2, "Professors" = 2)) |>
collapse_rows(columns = 1, valign = "top") |>
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")
              )
```

-   I can arrange my table to have an intuitive ordering

```{r}
#| label: dvs-6-ex-3

#Lab 4 Q5

mhi_by_region |>
  arrange(desc(`2018`))
```

**DVS-7: I show creativity in my tables.**

-   I can use non-default colors

```{r}
#| label: dvs-7-ex-1

# Lab 4: childcare prices by age group
#EDIT: used a pivot_longer to make table easier to read

plot_data <- ca_childcare |>
select(region, study_year, mc_infant, mc_toddler, mc_preschool) |>
pivot_longer(
cols      = c(mc_infant, mc_toddler, mc_preschool),
names_to  = "age_group",
values_to = "price_weekly"
)

head(plot_data)
```

-   I can modify the layout of my table to be more readable (e.g., `pivot_longer()` or `pivot_wider()`)

```{r}
#| label: dvs-7-ex-2

# Lab 4: median household income for 2008 vs 2018
#EDIT: use pivot_wider() to compare groups next to each other

mhi_by_region_wide <- mhi_by_region |>
pivot_wider(
names_from   = study_year,
values_from  = median_hh_income,
names_prefix = "mhi_"
)

mhi_by_region_wide
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

# Lab 4: defining California census regions with fct_collapse().
#EDIT: used one function call with lots of inputs to reduce repeatability

ca_childcare <- ca_childcare |>
mutate(county_name = str_remove(county_name, " County")) |>
mutate(
region = fct_collapse(
factor(county_name),
"Superior California"          = superior_counties,
"North Coast"                  = north_coast_counties,
"San Francisco Bay Area"       = san_fran_counties,
"Northern San Joaquin Valley"  = n_san_joaquin_counties,
"Central Coast"                = central_coast_counties,
"Southern San Joaquin Valley"  = s_san_joaquin_counties,
"Inland Empire"                = inland_counties,
"Los Angeles"                  = la_county,
"Orange"                       = orange_county,
"San Diego-Imperial"           = sandiego_imperial
)
)
```

-   using `across()`

```{r}
#| label: pe-1-across

# Lab 7: counting missing values for every column
#EDIT: concise code using summarize instead of repeating calls

missing_by_var <- fish |>
summarise(
across(everything(), ~ sum(is.na(.x)))
)

missing_by_var
```

-   using functions from the `map()` family

```{#| label: pe-1-map-1}

# Lab 10: map_int() to repeat sim 10,000 times

set.seed(123)
results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(4)
                   )
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Function that operates on vectors

```{#| label: pe-2-1}

# Challenge 7 Q3: function operating on a numeric vector

replace_outside <- function(x, min_val, max_val) {
  ifelse(
    test = !between(x, min_val, max_val),
    yes  = NA,
    no   = x
  )
}
```

-   Example 2: Function that operates on data frames

```{#| label: pe-2-2}

# Lab 8: function operating on a data frame

pivot_table <- function(df, row, col) {
  df |>
    drop_na({{ row }}, {{ col }}) |>
    count({{ row }}, {{ col }}) |>
    pivot_wider(
      names_from  = {{ col }},
      values_from = n,
      values_fill = 0
    ) |>
    arrange({{ row }})
}
```

-   Example 3: Function that operates on vectors *or* data frames

```{#| label: pe-2-3}

# Lab 7 Q4

rescale_01 <- function(x) {
  stopifnot(is.numeric(x))
  stopifnot(length(x) > 1)

  rng  <- range(x, na.rm = TRUE, finite = TRUE)
  span <- rng[2] - rng[1]

  if (span == 0) {
    return(
      case_when(
        is.na(x)     ~ NA,
        is.finite(x) ~ 0,
        TRUE         ~ NA
      )
    )
  }

  case_when(
    is.na(x)     ~ NA,
    x == -Inf    ~ 0,
    x ==  Inf    ~ 1,
    is.finite(x) ~ (x - rng[1]) / span
  )
}
```

**PE-3: I can use iteration to reduce repetition in my code.**

-   using `across()`

```{r}
#| label: pe-3-across

# Lab 7: summarizing numeric columns in fish data
#EDIT: across() used to compute means for many variables at one time

numeric_means <- fish |>
summarise(
across(where(is.numeric), ~ mean(.x, na.rm = TRUE))
)

numeric_means
```

-   using a `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

# Lab 10: running the random babies simulation 10000 times
#EDIT: map_int() used with one input to do sim several times

set.seed(123)

results <- map_int(.x = 1:10000,
.f = ~ randomBabies(4))

head(results)
```

-   using a `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{#| label: pe-3-map-2}

#Lab 10: vectors estimate and conf.low used together

estimates  <- ci_results$estimate
lower_vals <- ci_results$conf.low

map2_dbl(estimates, lower_vals, ~ .x - .y)
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

#Lab 4 Q7

plot_data <- ca_childcare |>
select(region, study_year, mc_infant, mc_toddler, mc_preschool) |>
pivot_longer(
cols = c(mc_infant, mc_toddler, mc_preschool),
names_to = "age_group",
values_to = "price_weekly"
) |>
mutate(
age_group = recode(age_group,
mc_infant = "Infant",
mc_toddler = "Toddler",
mc_preschool = "Preschool"),
age_group = fct_relevel(age_group, "Infant", "Toddler", "Preschool"),
region = fct_recode(region, "Los Angeles County" = "Los Angeles"),
region = fct_relevel(
region,
"San Francisco Bay Area",
"Orange",
"Los Angeles County",
"Northern San Joaquin Valley",
"Central Coast",
"Inland Empire",
"Superior California",
"Southern San Joaquin Valley",
"San Diego-Imperial",
"North Coast"
)
)

ggplot(plot_data, aes(x = study_year, y = price_weekly, color = region)) +
geom_point(alpha = 0.5, size = 1.5) +
geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
labs(
title = "Weekly Median Price for Center-Based Childcare",
x = "Year",
y = "Median Weekly Price",
color = "California Region"
) +
facet_wrap(~ age_group, nrow = 1)
```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

# Lab 4 Q7

ggplot(plot_data, aes(x = study_year, y = price_weekly, color = region)) +
  geom_point(alpha = 0.5, size = 1.5) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  facet_wrap(~ age_group, nrow = 1)
```

## Data Simulation & Statistical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

#Lab 10 Question 1

randomBabies <- function(n_babies) {
baby_ids <- 1:n_babies

assigned_ids <- sample(baby_ids, size = n_babies, replace = FALSE)

correct_matches <- sum(baby_ids == assigned_ids)

return(correct_matches)
}
```

-   Example 2

```{r}
#| label: dsm-1-2

#Lab 10 Question 1

set.seed(123)
results <- map_int(.x = 1:10000,
.f = ~ randomBabies(4))

head(results)
```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

#Lab 2 Q17-18

species_mod <- aov(weight ~ species, data = surveys)
summary(species_mod)
```

-   Example 2

```{r}
#| label: dsm-2-2

# Lab 3 Challenge 3: association between seniority and evaluation rating.
#EDIT: edited to show contingency table and then do X^2 test

eval_table <- table(teacher_evals_compare$set_level,
teacher_evals_compare$sen_level)

eval_table

chisq_result <- chisq.test(eval_table)
chisq_result
```

-   Example 3

```{r}
#| label: dsm-2-3

# Lab 2: modeling weight as a function of hindfoot length.
#EDIT: implemented linear regression

weight_model <- lm(weight ~ hindfoot_length, data = surveys)
summary(weight_model)
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

Throughout the course, I found myself revising my thinking on certain topics, particularly Joins. As I understood more about Joins, I realized that they have a close relationship with filters (specifically anti joins) and there could be times when they can be used interchangeably. While creating this portfolio, I made a few edits to my existing code in order for it to more closely demonstrate the learning target.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

So far throughout the course, I have extended my thinking on certain topics by seeking help from my classmates and utilizing websites and forums online that provided me extra help when needed. In creating this portfolio, I used some of the information that I obtained through the internet and classmates to increase code efficiency, make my code tidier, and find proper solutions to questions which I struggled with.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

I was particularly proud of a comment I left on Lab 4 code review where I was able to find a function in my peer's code that could have been replaced with a summarise() to increase their code's efficiency and it showed me that I had a good understanding of that specific function.

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

The weekly programming activities were highly beneficial for my learning in this course because it allowed me to help my classmates and solidify my knowledge through teaching/helping them, and allowed me to get help on things that I did not understand completely. It was also highly beneficial that while helping each other, we could ask Dr T or class helpers to get even further assistance.
